# ğŸ“° Real-Time News Analytics Pipeline

A **real-time news analytics system** built using **Apache Airflow, Apache Kafka, Apache Spark, and MongoDB**.

This pipeline fetches live news articles from the **News API**, streams them through **Kafka**, performs **sentiment analysis**, stores the processed data in **MongoDB**, and provides **CRUD operations** along with a **Gradio-based UI** to view results.

This project demonstrates an **end-to-end big data pipeline** using modern data engineering tools.

---

## ğŸš€ Features

- ğŸ”„ Real-time data ingestion from News API  
- ğŸ“¡ Streaming with Apache Kafka  
- âš™ï¸ Workflow orchestration using Apache Airflow  
- ğŸ§  Sentiment analysis using Apache Spark (PySpark) + TextBlob  
- ğŸ—„ï¸ MongoDB for persistent storage  
- âœï¸ CRUD operations (Create, Read, Update, Delete)  
- ğŸ–¥ï¸ Gradio UI for viewing news headlines and sentiment scores  
- ğŸ³ Docker-based setup for Kafka & MongoDB  

---

## ğŸ› ï¸ Technology Stack

| Layer          | Technology              |
|---------------|--------------------------|
| Orchestration | Apache Airflow           |
| Streaming     | Apache Kafka             |
| Processing    | Apache Spark (PySpark)   |
| NLP           | TextBlob                 |
| Database      | MongoDB                  |
| UI            | Gradio                   |
| Language      | Python                   |
| Deployment    | Docker                   |

---

## ğŸ“ Project Structure

```text
real-time-news-analytics-pipeline/
â”‚
â”œâ”€â”€ dags/                     # Airflow DAGs
â”‚   â””â”€â”€ airflow_dag.py
â”‚
â”œâ”€â”€ kafka/                    # Kafka producer & consumer
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â””â”€â”€ kafka_consumer.py
â”‚
â”œâ”€â”€ spark/                    # Spark processing logic
â”‚   â””â”€â”€ spark_processing.py
â”‚
â”œâ”€â”€ database/                 # MongoDB connection & CRUD
â”‚   â”œâ”€â”€ mongodb_connect.py
â”‚   â””â”€â”€ crud_operations.py
â”‚
â”œâ”€â”€ ui/                       # Gradio UI
â”‚   â””â”€â”€ gradio_ui.py
â”‚
â”œâ”€â”€ docker/                   # Docker configuration
â”‚   â””â”€â”€ compose.yml
â”‚
â”œâ”€â”€ logs/                     # Application logs
â”œâ”€â”€ docs/                     # Project documentation
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md 
```

---

## âš™ï¸ Setup Instructions (Windows)

### 1ï¸âƒ£ Prerequisites
Ensure the following are installed:
- Python **3.9 or 3.10**
- Docker Desktop (**WSL 2 enabled**)
- Java **JDK 8 or 11**
- Git

---

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/real-time-news-analytics-pipeline.git
cd real-time-news-analytics-pipeline
```

3ï¸âƒ£ Create Virtual Environment & Install Dependencies
```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

4ï¸âƒ£ Start Kafka & MongoDB (Docker)
```bash
cd docker
docker compose up -d
docker ps   #Verify
```

5ï¸âƒ£ Start Airflow Scheduler

Airflow webserver runs in Docker, but the scheduler must be started to execute DAGs.
``bash
docker exec -it airflow bash
airflow scheduler
```
ğŸ“Œ Keep this scheduler running in the terminal.

6ï¸âƒ£ Access Airflow UI
Open your browser:http://localhost:8080

Login credentials:
Username: admin
Password: admin
Enable the DAG: news_api_pipeline
Trigger the DAG manually â–¶

7ï¸âƒ£ Run Kafka Consumer
```bash
python kafka/kafka_consumer.py
#(Keep this terminal running)
```

8ï¸âƒ£ Run Kafka Producer
```bash
python kafka/kafka_producer.py
This fetches live news and streams it to Kafka.
```

9ï¸âƒ£ Verify MongoDB Storage
```bash
python database/crud_operations.py
```

ğŸ”Ÿ Run Gradio UI
```bash
python -m ui.gradio_ui
```

â° Airflow DAG
- DAG Name: news_api_pipeline
- Schedule: Hourly
- Task: Fetch news â†’ Publish to Kafka

ğŸ”„ Workflow Overview
- Airflow schedules the pipeline
- Kafka Producer fetches news from News API
- Kafka Consumer receives articles
- Spark processes text and computes sentiment
- MongoDB stores processed articles
- Gradio UI displays results

ğŸ“Š Sample Output
- Title: News headline
- Sentiment Score: Range from -1 (negative) to +1 (positive)